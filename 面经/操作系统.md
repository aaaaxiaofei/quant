# 操作系统面经

## 知识点总结
- [jiangren](https://jiangren.work/2020/02/16/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE%E6%B1%87%E6%80%BB/)

## 常见题
- [zhihu](https://zhuanlan.zhihu.com/p/23755202)
- [nowcoder](https://blog.nowcoder.net/n/49211c67aaaa49eb8842f7e979c79498)
- [csdn](https://blog.csdn.net/justloveyou_/article/details/78304294)
- [aliyun](https://developer.aliyun.com/article/133729)
- [huawei](https://www.nowcoder.com/discuss/325668?type=5)
- [jianshu](https://www.jianshu.com/p/f347af8919cb)
- [juejin](https://juejin.cn/post/6844903478859431943)


### 综合面经 - 操作系统部分
- [here](https://github.com/huihut/interview#-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F)
- 资源调度最小独立单位？
- 进程通信方式？优缺点？
- What is Semaphore?
- What is signal?
- What is message queue?
- Shared memory? How to create shared memory?
- Socket? Pros vs Cons?
- 进程之间共享资源，私有资源？
- 线程之间共享资源，私有资源？
- 多进程与多线程优劣？如何选择？

- Linux kernel同步
- Cache? layer?

- Deadlock? How? Example? How to prevent? How to solve?

- Linux file system? Inode + index?
- Windows file system? FCB table

- endianness (字节序) big or little? how to tell? 
- why network uses big endian?

### 其他问题
- 页面置换算法?
- virtual memory
- How thread sycronization?
- linux内存状态的代码
- 多线程下对数据库的访问拥堵怎么解决
- [system call](https://www.geeksforgeeks.org/introduction-of-system-call/#:~:text=A%20system%20call%20is%20a,Application%20Program%20Interface(API).)

- How thread communicate?
 	- lock
 	- semaphore
 	- signal
 	- barrier

### 进程线程面试题总结
 - [here](https://blog.csdn.net/wujiafei_njgcxy/article/details/77098977)
 - 有一个全局变量int a=0，现在两个线程各自循环执行100次a++操作，问最后a的值是多少？
什么是阻塞，什么是非阻塞？
什么是同步，什么是异步？
什么情况下使用线程锁？
进程与线程的区别?
进程间通信有那几种，线程通信有那几种，以及各自的优势？
消息队列
消息有哪些瓶颈？

序列化
什么是序列化
常用序列化方式都有哪些

# 知识点总结
OS notes:
http://personal.kent.edu/~rmuhamma/OpSystems/os.html

## Process
A process is only ONE instant of a program in execution.
进程是资源分配的最小单位，线程是CPU调度的最小单位

### Different state of process
	New
	This is the state when the process has just been created. It is the initial state in the process life cycle.

	Ready
	In the ready state, the process is waiting to be assigned the processor by the short term scheduler, so it can run. This state is immediately after the new state for the process.

	Ready Suspended
	The processes in ready suspended state are in secondary memory. They were initially in the ready state in main memory but lack of memory forced them to be suspended and gets placed in the secondary memory.

	Running
	The process is said to be in running state when the process instructions are being executed by the processor. This is done once the process is assigned to the processor using the short-term scheduler.

	Blocked
	The process is in blocked state if it is waiting for some event to occur. This event may be I/O as the I/O events are executed in the main memory and don't require the processor. After the event is complete, the process again goes to ready state.

	Blocked Suspended
	This is similar to ready suspended. The processes in blocked suspended state are in secondary memory. They were initially in the blocked state in main memory waiting for some event but lack of memory forced them to be suspended and gets placed in the secondary memory. A process may go from blocked suspended to ready suspended if its work is done.

	Terminated
	The process is terminated once it finishes its execution. In the terminated state, the process is removed from main memory and its process control block is also deleted.

### Process states transition
	Transition 1 occurs when process discovers that it cannot continue. If running process initiates an I/O operation before its allotted time expires, the running process voluntarily relinquishes the CPU.This state transition is: Block (process-name): Running → Block.
	 
	Transition 2 occurs when the scheduler decides that the running process has run long enough and it is time to let another process have CPU time. This state transition is: Time-Run-Out  (process-name): Running → Ready.
	 
	Transition 3 occurs when all other processes have had their share and it is time for the first process to run again This state transition is:  Dispatch (process-name): Ready → Running.
	 
	Transition 4 occurs when the external event for which a process was waiting (such as arrival of input) happens.This state transition is: Wakeup (process-name): Blocked → Ready.
	 
	Transition 5 occurs when the process is created. This state transition is: Admitted (process-name): New → Ready.
	 
	Transition 6 occurs when the process has finished execution. This state transition is: Exit (process-name): Running → Terminated.

### IPC(Inter process communication)
- Semaphore
- Pipe (named pipe, unnamed pipe)
- Message queue
	- If more than one process (or thread) is waiting to receive a message when a message arrives at an empty queue, then the process of highest priority that has been waiting the longest is selected to receive the message. 
- Shared memory


### PV讲解，苹果，和尚打水
 - [here](https://zhuanlan.zhihu.com/p/61326272)

### 进程间同步
- critical-section： 每个进程必须请求允许进入其临界区（critical section）。实现此请求的代码段是入口区（entry section）。临界区（critical section）之后则是出口区（exit section）。
- 互斥量 （mutex)
- 信号量 (semaphore)
- 事件 (event)： 通过通知操作的方式来保持线程的同步

### 线程间同步
- 互斥量
- 信号量，只能用于一个资源的互斥访问，不能实现多个资源的多线程互斥问题
- 读写锁 (read write lock)，可以被多个读者拥有，但是只能被一个写者拥有的锁
- 条件变量，线程 A 等待某个条件并挂起，直到线程 B 设置了这个条件，并通知条件变量，然后线程 A 被唤醒
- 原子操作 (atomic operations)
- 通道

### 线程池
处理完之后线程并不会被销毁，而是等待下一个任务。由于创建和销毁线程都是消耗系统资源的，所以池化技术能提升性能。

### process control block (PCB) 
	The current state of the process i.e., whether it is ready, running, waiting, or whatever.
	Unique identification of the process in order to track "which is which" information.
	A pointer to parent process.
	Similarly, a pointer to child process (if it exists).
	The priority of process (a part of CPU scheduling information).
	Pointers to locate memory of processes.
	A register save area.
	The processor it is running on.

### How is a process stored in memory:
 - Stack: The process Stack contains the temporary data such as method/function parameters, return address and local variables.
 - Heap: This is dynamically allocated memory to a process during its run time.
 - Text: This includes the current activity represented by the value of Program Counter and the contents of the processor's registers.
 - Data: This section contains the global and static variables.

## Scheduling

### Preemptive
These algorithms are either non-preemptive or preemptive. Non-preemptive algorithms are designed so that once a process enters the running state, it cannot be preempted until it completes its allotted time, whereas the preemptive scheduling is based on priority where a scheduler may preempt a low priority running process anytime when a high priority process enters into a ready state.

### Process Scheduling
The OS maintains all PCBs in Process Scheduling Queues
- Job queue
- Ready queue
- I/O waiting queue

### Schedulers
- Long term: job scheduler
- Short term: CPU scheduler
- Medium term: Swap out

### Schedule Algorighm
 - First-Come, First-Served (FCFS) Scheduling
 - Shortest-Job-Next (SJN) Scheduling
 - Priority Scheduling
 - Shortest Remaining Time
 - Round Robin(RR) Scheduling
 - Multiple-Level Queues Scheduling

### Context Switch
Keep track of the status of current process, resume later:
- Program Counter
- Scheduling information
- Base and limit register value
- Currently used register
- Changed State
- I/O State information
- Accounting information


### Thread control block (TCB)


## Thread
A thread is also called a lightweight process. Each thread belongs to exactly one process and no thread can exist outside a process.

each thread will have its own stack, but all the threads in a process will share the heap

### Process vs Thread

| Process | Thread |
| ------- | ------ |
| Process is heavy weight or resource intensive. | Thread is light weight, taking lesser resources than a process. |
| Process switching needs interaction with operating system | Thread switching does not need to interact with operating system. |
| In multiple processing environments, each process executes the same code but has its own memory and file resources | All threads can share same set of open files, child processes. |
| If one process is blocked, then no other process can execute until the first process is unblocked. | While one thread is blocked and waiting, a second thread in the same task can run. |
| Multiple processes without using threads use more resources. | Multiple threaded processes use fewer resources. |
| In multiple processes each process operates independently of the others. | One thread can read, write or change another thread's data. |
	
### Advantages of Thread
 - Threads minimize the context switching time.
 - Use of threads provides concurrency within a process.
 - Efficient communication.
 - It is more economical to create and context switch threads.
 - Threads allow utilization of multiprocessor architectures to a greater scale and efficiency.

### Kernel level thread vs User Level thread


### Deadlock

#### Necessary conditions for deadlock
- Mutual exclusion: At least one resource must be held in a non-shareable mode. Otherwise, the processes would not be prevented from using the resource when necessary. Only one process can use the resource at any given instant of time.[6]
- Hold and wait or resource holding: a process is currently holding at least one resource and requesting additional resources which are being held by other processes.
- No preemption: a resource can be released only voluntarily by the process holding it.
- Circular wait: each process must be waiting for a resource which is being held by another process, which in turn is waiting for the first process to release the resource. In general, there is a set of waiting processes, P = {P1, P2, …, PN}, such that P1 is waiting for a resource held by P2, P2 is waiting for a resource held by P3 and so on until PN is waiting for a resource held by P1.[3][7]

## Memory Management

-逻辑地址（Logic Address）是指由程序产生的与段相关的偏移地址部分，因此一个逻辑地址由段标识符和段内偏移量组成，有时也称虚拟地址。比如，在C程序中，可以使用&操作读取指针变量本身的值，实际上这个值就是逻辑地址。逻辑地址和绝对的物理地址不相干。

-线性地址（Linear Address） 是逻辑地址到物理地址变换之间的中间层。 程序代码会产生逻辑地址， 或说是段中的偏移地址， 加上相应段的基地址就生成了一个线性地址。

- 物理地址（Physical Address）是CPU外部地址总线上的地址，也是地址变换的最终地址

### 寻址方式有哪些 ??

### 分页分段的区别是什么？
- 属性：页是信息的物理单位，对用户不可见，段是逻辑单位，用户可见。
- 大小：分页固定，分段不固定
- 决定权：分页在于系统，分段在于用户
- 目的：分页有利于资源的利用，分段方便用户管理内存

### 有哪些页面置换算法？
- 先进先出FIFO：总是选择在主存中停留时间最长（即最老）的一页置换
- LRU：选择在最近一段时间里最久没有使用过的页面予以置换
- LFU(least frequent)：统计页的使用频率，选择在最近时期使用最少的页面作为淘汰页

### Static vs Dynamic Loading
- At the time of loading, with static loading, the absolute program (and data) is loaded into memory in order for execution to start.
- If you are using dynamic loading, dynamic routines of the library are stored on a disk in relocatable form and are loaded into memory only when they are needed by the program.

### Static vs Dynamic Linking
- when static linking is used, the linker combines all other modules needed by a program into a single executable program to avoid any runtime dependency.
- When dynamic linking is used, it is not required to link the actual module or library with the program, rather a reference to the dynamic module is provided at the time of compilation and linking. Dynamic Link Libraries (DLL) in Windows and Shared Objects in Unix are good examples of dynamic libraries.

### Swapping
Swapping is a mechanism in which a process can be swapped temporarily out of main memory (or move) to secondary storage (disk) and make that memory available to other processes.

### Main memory usually has two partitions
- Low Memory − Operating system resides in this memory.
- High Memory − User processes are held in high memory.

### Fragmentation
- External fragmentation: Total memory space is enough to satisfy a request or to reside a process in it, but it is not contiguous, so it cannot be used.
- Internal fragmentation: Memory block assigned to process is bigger. Some portion of memory is left unused, as it cannot be used by another process.

### Paging
Paging is a memory management technique in which process address space is broken into blocks of the same size called pages.
main memory is divided into small fixed-sized blocks of (physical) memory called frames

### Advantages and Disadvantages of Paging
- Paging reduces external fragmentation, but still suffer from internal fragmentation.
- Paging is simple to implement and assumed as an efficient memory management technique.
- Due to equal size of the pages and frames, swapping becomes very easy.
- Page table requires extra memory space, so may not be good for a system having small RAM.

### Segmentation
Segmentation is a memory management technique in which each job is divided into several segments of different sizes, one for each module that contains pieces that perform related functions. Each segment is actually a different logical address space of the program.
When a process is to be executed, its corresponding segmentation are loaded into non-contiguous memory though every segment is loaded into a contiguous block of available memory.
The operating system maintains a segment map table for every process

### Virtual Memory
A computer can address more memory than the amount physically installed on the system. This extra memory is actually called virtual memory and it is a section of a hard disk that's set up to emulate the computer's RAM.

- How is virtual memory implemented?
	- Virtual memory is commonly implemented by demand paging

- Advantage:
	- Large virtual memory.
	- More efficient use of memory.
	- There is no limit on degree of multiprogramming.
- Disadvantage
	- Number of tables and the amount of processor overhead for handling page interrupts are greater than in the case of the simple paged management techniques.

### Page fault
if the program references a page which is not available in the main memory because it was swapped out a little ago, the processor treats this invalid memory reference as a page fault


## I/O
### Polling vs Interrupts
- The process of periodically checking status of the device to see if it is time for the next I/O operation
- An alternative scheme for dealing with I/O is the interrupt-driven method. An interrupt is a signal to the microprocessor from a device that requires attention.

## Operating System
### What is an operating system
system software that manages computer hardware, software resources, and provides common services for computer programs.

### What is kernel
core of a computer's operating system that has complete control over everything in the system.
Kernel is responsible for low-level tasks such as disk management, memory management, task management
The kernel responds to service calls from the processes and interrupts from the devices and traps from processes

### What is monolithic kernel?
A monolithic kernel is a kernel which includes all operating system code is in single executable image.

### Operating System Components
Process Management
Main-Memory Management
File Management
I/O System Management
Secondary-Storage Management

### What is program counter?
A program counter is a register in a computer processor that contains the address (location) of the instruction being executed at the current time. As each instruction gets fetched, the program counter increases its stored value by 1.

#### Spooling

## Process scheduling
Traffic controller allocate CPU to process, and decide how much time

### Primary, secondary, cache storage
Instructions and data must be placed in primary storage or cache to be referenced by a running program. Because main memory is too small to accommodate all data and programs, and its data are lost when power is lost, the computer system must provide secondary storage to back up main memory. Secondary storage consists of tapes, disks, and other media designed to hold information that will eventually be accessed in primary storage

### System Call
System calls provide an interface between the process an the operating system. System calls allow user-level processes to request some services from the operating system which process itself is not allowed to do. (the operating system will enter in the kernel mode)

## Interrupt
- 保护现场：将当前执行程序的相关数据保存在寄存器中，然后入栈
- 开中断：以便执行中断时能响应较高级别的中断请求。
- 中断处理
- 关中断：保证恢复现场时不被新中断打扰
- 恢复现场：从堆栈中按序取出程序数据，恢复中断前的执行状态。

### polling or interrupt
轮询：CPU对特定设备轮流询问。中断：通过特定事件提醒CPU。
轮询：效率低等待时间长，CPU利用率不高。中断：容易遗漏问题，CPU利用率不高。

## Networking
